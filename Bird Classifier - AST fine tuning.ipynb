{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tt9NvyqDd8Bx"
   },
   "source": [
    "## Reference\n",
    "\n",
    "[Ultimate Guide to Fine-Tuning in PyTorch : Part 1 ‚Äî Pre-trained Model and Its Configuration](https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e)\n",
    "\n",
    "[Training a PyTorch Model with DataLoader and Dataset](https://machinelearningmastery.com/training-a-pytorch-model-with-dataloader-and-dataset/)\n",
    "\n",
    "[LoRA](https://huggingface.co/docs/peft/conceptual_guides/lora)\n",
    "\n",
    "[PEFT](https://huggingface.co/docs/peft/index)\n",
    "\n",
    "[Image classification using LoRA](https://huggingface.co/docs/peft/task_guides/image_classification_lora)\n",
    "\n",
    "[AST clasifiers](https://huggingface.co/models?pipeline_tag=audio-classification&sort=downloads&search=ast)\n",
    "\n",
    "[PEFT Quicktour](https://huggingface.co/docs/peft/quicktour)\n",
    "\n",
    "[Initialize Model with Adapters](https://docs.adapterhub.ml/quickstart.html)\n",
    "\n",
    "[Fine-tuning for Audio Classification with ü§ó Transformers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK_DP9ZEfpi4"
   },
   "source": [
    "## imports and functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48782,
     "status": "ok",
     "timestamp": 1706431219838,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "t-9v-MwxeRxv",
    "outputId": "25abf6a0-c3bf-472f-c206-3c7909ce9563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.10.0-py3-none-any.whl (19.5 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
      "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
      "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
      "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
      "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
      "Collecting querystring-parser<2 (from mlflow)\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.24)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.2)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
      "Collecting gunicorn<22 (from mlflow)\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
      "Successfully installed Mako-1.3.0 alembic-1.13.1 databricks-cli-0.18.0 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.41 gunicorn-21.2.0 mlflow-2.10.0 querystring-parser-1.2.4 smmap-5.0.1\n",
      "Username: tl_vasilev@yahoo.com\n",
      "Password: \n",
      "Repeat for confirmation: \n",
      "Collecting adapters\n",
      "  Downloading adapters-0.1.1-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers~=4.35.2 in /usr/local/lib/python3.10/dist-packages (from adapters) (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.35.2->adapters) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers~=4.35.2->adapters) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers~=4.35.2->adapters) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.35.2->adapters) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.35.2->adapters) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.35.2->adapters) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.35.2->adapters) (2023.11.17)\n",
      "Installing collected packages: adapters\n",
      "Successfully installed adapters-0.1.1\n",
      "Collecting peft\n",
      "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-0.26.1 peft-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "!databricks configure --host https://community.cloud.databricks.com/\n",
    "!pip install adapters\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yD6xOncB6Kl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.colab import drive\n",
    "from transformers import ASTFeatureExtractor, AutoProcessor, ASTModel, AutoModelForAudioClassification\n",
    "from adapters import AdapterConfig\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from numba import cuda\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "import mlflow\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1706431237567,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "Y8e1uTj3criO",
    "outputId": "72881ca7-2980-43b1-e663-d631c691f2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/392919980505162', creation_time=1705679888584, experiment_id='392919980505162', last_update_time=1706431115432, lifecycle_stage='active', name='/Users/tl_vasilev@yahoo.com/birds2023', tags={'mlflow.experiment.sourceName': '/Users/tl_vasilev@yahoo.com/birds2023',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'tl_vasilev@yahoo.com',\n",
       " 'mlflow.ownerId': '4375994119615411'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/Users/tl_vasilev@yahoo.com/birds2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76RPY_uCJT-G"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TomasAST_1(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TomasAST_1, self).__init__()\n",
    "        # self.part1 = model.audio_spectrogram_transformer\n",
    "        self.part1 = model\n",
    "        self.part2 = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part3 = nn.Linear(in_features=768, out_features=384, bias=True)\n",
    "        self.part4 = nn.LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part5 = nn.Linear(in_features=384, out_features=120, bias=True)\n",
    "        self.part6 = nn.LayerNorm((120,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part7 = nn.Linear(in_features=120, out_features=40, bias=True)\n",
    "        self.part8 = nn.LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part9 = nn.Linear(in_features=40, out_features=11, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.part1(x)\n",
    "      x = self.part2(x[1])\n",
    "      x = F.relu(self.part3(x))\n",
    "      x = self.part4(x)\n",
    "      x = F.relu(self.part5(x))\n",
    "      x = self.part6(x)\n",
    "      x =F.relu( self.part7(x))\n",
    "      x = self.part8(x)\n",
    "      x = self.part9(x)\n",
    "      return x\n",
    "\n",
    "class TomasAST_2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TomasAST_2, self).__init__()\n",
    "        # self.part1 = model.audio_spectrogram_transformer\n",
    "        self.part1 = model\n",
    "        self.part2 = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part3 = nn.Linear(in_features=768, out_features=160, bias=True)\n",
    "        self.part4 = nn.LayerNorm((160,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part5 = nn.Linear(in_features=160, out_features=11, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.part1(x)\n",
    "      x = self.part2(x[1])\n",
    "      x = F.relu(self.part3(x))\n",
    "      x = self.part4(x)\n",
    "      x = self.part5(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKcnwIlvCDLz"
   },
   "outputs": [],
   "source": [
    "class CustomAST(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomAST, self).__init__()\n",
    "        # self.part1 = model.audio_spectrogram_transformer\n",
    "        self.part1 = model\n",
    "        self.part2 = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part3 = nn.Linear(in_features=768, out_features=11, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.part1(x)\n",
    "      x = self.part2(x[1])\n",
    "      x = self.part3(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        features = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    # acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, lr = 0.01, momentum=0.9, weight_decay=0.001,\n",
    "                run_name = 'basic model', n_epochs = 1, lr_decrese = False  ):\n",
    "  try:\n",
    "\n",
    "    mlflow.start_run(run_name = run_name)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.001)\n",
    "      # number of epochs to run\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss_list = [ [] for _ in range(n_epochs) ]\n",
    "    accuracy = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "      if (epoch+1) == n_epochs and lr_decrese == True : lr = lr/10 # the learning rate in the last epoch will be smaller so teht we can find better the minimum\n",
    "      optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      loss_list[epoch] = []\n",
    "      for Xbatch, ybatch in tqdm(train_loader):\n",
    "        # forward pass\n",
    "        y_pred = model(Xbatch.to(device))\n",
    "        # loss = loss_fn(y_pred.logits, ybatch.to(device))\n",
    "        loss = loss_fn(y_pred, ybatch.to(device))\n",
    "        # # L1 regularization\n",
    "        # regularization_loss = 0.0\n",
    "      # for param in model.parameters():\n",
    "        #   regularization_loss += torch.norm(param, 1)\n",
    "        # loss += 0.01 * regularization_loss#Adjust regularization strength as needed\n",
    "        # print(loss)\n",
    "        mlflow.log_metric(f\"train_loss_ep{epoch}\", loss)\n",
    "        loss_list[epoch].append(loss)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "      # validation\n",
    "      with torch.no_grad():\n",
    "        for x_val_b, y_val_b in val_loader:\n",
    "          y_pred_b = model(x_val_b.to(device))\n",
    "          accuracy.append(multi_acc(y_pred_b, y_val_b.to(device)))\n",
    "        mlflow.log_metric(f\"Accuracy_val_ep\", sum(accuracy)/len(accuracy))\n",
    "        mlflow.log_param(f'lr_epoch{epoch+1}', lr)\n",
    "        print(f'Epoch {epoch+1} Accuracy = {sum(accuracy)/len(accuracy)}')\n",
    "    mlflow.end_run()\n",
    "  except :\n",
    "    print('stopping mlflow run')\n",
    "    mlflow.end_run()\n",
    "\n",
    "def predict_model(model,test_loader):\n",
    "    model.eval()\n",
    "    accuracy = []\n",
    "    with torch.no_grad():\n",
    "      for x_test_b, y_test_b in tqdm(test_loader):\n",
    "        y_pred_b = model(x_test_b.to(device))\n",
    "        accuracy.append(multi_acc(y_pred_b, y_test_b.to(device)))\n",
    "      print(f'Test Accuracy = {sum(accuracy)/len(accuracy)}')\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lho4YG6mumm3"
   },
   "source": [
    "# Bird sound classifier using AST pre-trained model and fine-tuned with LoRA.\n",
    "\n",
    "[The Whole project with the data can be found here](https://drive.google.com/drive/folders/1YGw6GGCBEjsg3dFgiEruD7szzUpMcSVW?usp=sharing)\n",
    "\n",
    "We have already prepared the input data in \"Bird Clssifier - Pytorch Data preparation.ipynp\" using the AST feature extractor and saving the tesnsors with the input data. Here we will focus on the Finetuning.\n",
    "\n",
    "Audio Spectrogram Transformer (AST) is presented as the first convolution-free, purely attention-based model for Audio classification. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The used Audio Spectrogram Transformer (AST) model is fine-tuned on AudioSet and was introduced in the paper [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7cBmqy-v0Az"
   },
   "source": [
    "<a id='tops'></a>\n",
    "## Content\n",
    "\n",
    "* [Loading training and test data, loading the pre-trained models](#ld)\n",
    "* [Train and test pre-trained AST model with my custom classifier head](#my_model)\n",
    "* [Adaptation using LoRA ( Low-Rank Adaptation) on my model](#lora)\n",
    "* [Bigger head does not produce better results](#heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUtdsLf2w1R9"
   },
   "source": [
    "<a id='ld'></a>\n",
    "[TOP](#tops)\n",
    "## Loading training and test data, loading the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19574,
     "status": "ok",
     "timestamp": 1706431257135,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "7G1SQ41KEk9s",
    "outputId": "50d57a58-61b1-4a57-cfa8-2a1af52c9078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/MyDrive/Colab Notebooks/Birds2023\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/MyDrive/Colab Notebooks/Birds2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254,
     "referenced_widgets": [
      "116f2f3931df47f9a26ae9393636419b",
      "754266195a2b4593b3c6aa5ff6033c92",
      "b8025815f0ab4c01b5e1b4f517078640",
      "9715ac438e284272b5f960bcf0074d91",
      "190f08c51419465fabe83119cefdc4a8",
      "8473cba201984b64b6b1566f9424ace0",
      "f24baf67c4e64e13ae2ccb31a4476146",
      "1d224f159ccb4c7b8a09d4be369ba11c",
      "144f2baa82254a2b98755b646a0b84bd",
      "566bc31567a84713885a6521ffa956b2",
      "e199485560884c7b8051c5f0170e1ac7",
      "9de97399f81c4aa7b667ea3b12e7f666",
      "76a8266814464115b36c107002763421",
      "ee9f499d668e4ad2b272c93087802aa9",
      "8945c5cc80ca4b8cb0927f1a3f41a254",
      "d2df2603ba174484a462c631629d0f0c",
      "524a9a68c8bd4343926e88debdd06b0d",
      "b7a572065cf84f5fa16ea97e35600e9f",
      "5bb3546d5be8441fa7809622fd3afbb4",
      "f946159f57e7446eb971dc6d1783047e",
      "c8478567ff384b3aa4b25ee5494aaae2",
      "810fe31d22c740a5a604588ca17e67a0",
      "ce75bc4d57a04bbaa27e1679c1d83fb7",
      "51d5fb7fac2144059662e8f953af306e",
      "7b7beeae8b004c76803dc9e355cc1c24",
      "797d4f9f4e8d4754913c52695f3d3943",
      "772d0bc227af43528b256b31c19f6e3c",
      "44dc9d65a17a4cb8aa356b4633906f89",
      "4ae316d8c2b644ac904cfa322cfd33e0",
      "5bbd0d71ae644bab90ab82d9347b9001",
      "79946a9fb1da4321858b0b386df0647b",
      "1afe9ff6829a41c292444f1256a46190",
      "393127ec643e4012a13772138b718692"
     ]
    },
    "executionInfo": {
     "elapsed": 14187,
     "status": "ok",
     "timestamp": 1706431271317,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "Ii8W9GqdCDV0",
    "outputId": "9e571f92-1067-4d82-d15d-96baedebc48b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116f2f3931df47f9a26ae9393636419b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de97399f81c4aa7b667ea3b12e7f666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce75bc4d57a04bbaa27e1679c1d83fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "ast_model_classifier = AutoModelForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "# AST model with a pretrained head classifier\n",
    "feature_extractor = ASTFeatureExtractor()\n",
    "processor = AutoProcessor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "ast_model_pure = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\") # AST model without head classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_AXHHLvpUuZ"
   },
   "source": [
    "<b>We will load our datasets into the CPU and then run the training on the GPU</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706431271318,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "nDCj3QZRCJ-L",
    "outputId": "16cd1b27-8b77-4193-d234-1d72a1444ae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ir0i-HWCPZU"
   },
   "outputs": [],
   "source": [
    "x_tr = torch.load('X_train_tensor.pt')\n",
    "y_tr = torch.load('y_train_tensor.pt')\n",
    "x_val = torch.load('X_test_tensor.pt')\n",
    "y_val = torch.load('y_test_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbJInVpdy87M"
   },
   "source": [
    "<a id='my_model'></a>\n",
    "[TOP](#tops)\n",
    "## Train and test pre-trained AST model with my custom classifier head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go9Gl-TAyJue"
   },
   "source": [
    "<b>Split the test data from previous chapterinto validation 30% and test 70% sets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDluYQSWyINd"
   },
   "outputs": [],
   "source": [
    "testset, valset = random_split(BirdDataset(x_val, y_val), [0.7, 0.3])\n",
    "val_loader = DataLoader(valset, shuffle=True, batch_size=20)\n",
    "test_loader = DataLoader(testset, shuffle=True, batch_size=20)\n",
    "# train_loader = DataLoader((x_tr, y_tr), shuffle=True, batch_size=40)\n",
    "train_loader = DataLoader(BirdDataset(x_tr, y_tr), shuffle=True, batch_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LibYY3Psk2-e"
   },
   "source": [
    "We will Freeze teh layers that are coming from teh AST transformer.<br>\n",
    "Leaving only our custom Head as trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1705932812496,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "iYUykLZZEuXp",
    "outputId": "0da05799-43da-4a03-b3db-267407ee0b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part1.embeddings.cls_token False\n",
      "part1.embeddings.distillation_token False\n",
      "part1.embeddings.position_embeddings False\n",
      "part1.embeddings.patch_embeddings.projection.weight False\n",
      "part1.embeddings.patch_embeddings.projection.bias False\n",
      "part1.encoder.layer.0.attention.attention.query.weight False\n",
      "part1.encoder.layer.0.attention.attention.query.bias False\n",
      "part1.encoder.layer.0.attention.attention.key.weight False\n",
      "part1.encoder.layer.0.attention.attention.key.bias False\n",
      "part1.encoder.layer.0.attention.attention.value.weight False\n",
      "part1.encoder.layer.0.attention.attention.value.bias False\n",
      "part1.encoder.layer.0.attention.output.dense.weight False\n",
      "part1.encoder.layer.0.attention.output.dense.bias False\n",
      "part1.encoder.layer.0.intermediate.dense.weight False\n",
      "part1.encoder.layer.0.intermediate.dense.bias False\n",
      "part1.encoder.layer.0.output.dense.weight False\n",
      "part1.encoder.layer.0.output.dense.bias False\n",
      "part1.encoder.layer.0.layernorm_before.weight False\n",
      "part1.encoder.layer.0.layernorm_before.bias False\n",
      "part1.encoder.layer.0.layernorm_after.weight False\n",
      "part1.encoder.layer.0.layernorm_after.bias False\n",
      "part1.encoder.layer.1.attention.attention.query.weight False\n",
      "part1.encoder.layer.1.attention.attention.query.bias False\n",
      "part1.encoder.layer.1.attention.attention.key.weight False\n",
      "part1.encoder.layer.1.attention.attention.key.bias False\n",
      "part1.encoder.layer.1.attention.attention.value.weight False\n",
      "part1.encoder.layer.1.attention.attention.value.bias False\n",
      "part1.encoder.layer.1.attention.output.dense.weight False\n",
      "part1.encoder.layer.1.attention.output.dense.bias False\n",
      "part1.encoder.layer.1.intermediate.dense.weight False\n",
      "part1.encoder.layer.1.intermediate.dense.bias False\n",
      "part1.encoder.layer.1.output.dense.weight False\n",
      "part1.encoder.layer.1.output.dense.bias False\n",
      "part1.encoder.layer.1.layernorm_before.weight False\n",
      "part1.encoder.layer.1.layernorm_before.bias False\n",
      "part1.encoder.layer.1.layernorm_after.weight False\n",
      "part1.encoder.layer.1.layernorm_after.bias False\n",
      "part1.encoder.layer.2.attention.attention.query.weight False\n",
      "part1.encoder.layer.2.attention.attention.query.bias False\n",
      "part1.encoder.layer.2.attention.attention.key.weight False\n",
      "part1.encoder.layer.2.attention.attention.key.bias False\n",
      "part1.encoder.layer.2.attention.attention.value.weight False\n",
      "part1.encoder.layer.2.attention.attention.value.bias False\n",
      "part1.encoder.layer.2.attention.output.dense.weight False\n",
      "part1.encoder.layer.2.attention.output.dense.bias False\n",
      "part1.encoder.layer.2.intermediate.dense.weight False\n",
      "part1.encoder.layer.2.intermediate.dense.bias False\n",
      "part1.encoder.layer.2.output.dense.weight False\n",
      "part1.encoder.layer.2.output.dense.bias False\n",
      "part1.encoder.layer.2.layernorm_before.weight False\n",
      "part1.encoder.layer.2.layernorm_before.bias False\n",
      "part1.encoder.layer.2.layernorm_after.weight False\n",
      "part1.encoder.layer.2.layernorm_after.bias False\n",
      "part1.encoder.layer.3.attention.attention.query.weight False\n",
      "part1.encoder.layer.3.attention.attention.query.bias False\n",
      "part1.encoder.layer.3.attention.attention.key.weight False\n",
      "part1.encoder.layer.3.attention.attention.key.bias False\n",
      "part1.encoder.layer.3.attention.attention.value.weight False\n",
      "part1.encoder.layer.3.attention.attention.value.bias False\n",
      "part1.encoder.layer.3.attention.output.dense.weight False\n",
      "part1.encoder.layer.3.attention.output.dense.bias False\n",
      "part1.encoder.layer.3.intermediate.dense.weight False\n",
      "part1.encoder.layer.3.intermediate.dense.bias False\n",
      "part1.encoder.layer.3.output.dense.weight False\n",
      "part1.encoder.layer.3.output.dense.bias False\n",
      "part1.encoder.layer.3.layernorm_before.weight False\n",
      "part1.encoder.layer.3.layernorm_before.bias False\n",
      "part1.encoder.layer.3.layernorm_after.weight False\n",
      "part1.encoder.layer.3.layernorm_after.bias False\n",
      "part1.encoder.layer.4.attention.attention.query.weight False\n",
      "part1.encoder.layer.4.attention.attention.query.bias False\n",
      "part1.encoder.layer.4.attention.attention.key.weight False\n",
      "part1.encoder.layer.4.attention.attention.key.bias False\n",
      "part1.encoder.layer.4.attention.attention.value.weight False\n",
      "part1.encoder.layer.4.attention.attention.value.bias False\n",
      "part1.encoder.layer.4.attention.output.dense.weight False\n",
      "part1.encoder.layer.4.attention.output.dense.bias False\n",
      "part1.encoder.layer.4.intermediate.dense.weight False\n",
      "part1.encoder.layer.4.intermediate.dense.bias False\n",
      "part1.encoder.layer.4.output.dense.weight False\n",
      "part1.encoder.layer.4.output.dense.bias False\n",
      "part1.encoder.layer.4.layernorm_before.weight False\n",
      "part1.encoder.layer.4.layernorm_before.bias False\n",
      "part1.encoder.layer.4.layernorm_after.weight False\n",
      "part1.encoder.layer.4.layernorm_after.bias False\n",
      "part1.encoder.layer.5.attention.attention.query.weight False\n",
      "part1.encoder.layer.5.attention.attention.query.bias False\n",
      "part1.encoder.layer.5.attention.attention.key.weight False\n",
      "part1.encoder.layer.5.attention.attention.key.bias False\n",
      "part1.encoder.layer.5.attention.attention.value.weight False\n",
      "part1.encoder.layer.5.attention.attention.value.bias False\n",
      "part1.encoder.layer.5.attention.output.dense.weight False\n",
      "part1.encoder.layer.5.attention.output.dense.bias False\n",
      "part1.encoder.layer.5.intermediate.dense.weight False\n",
      "part1.encoder.layer.5.intermediate.dense.bias False\n",
      "part1.encoder.layer.5.output.dense.weight False\n",
      "part1.encoder.layer.5.output.dense.bias False\n",
      "part1.encoder.layer.5.layernorm_before.weight False\n",
      "part1.encoder.layer.5.layernorm_before.bias False\n",
      "part1.encoder.layer.5.layernorm_after.weight False\n",
      "part1.encoder.layer.5.layernorm_after.bias False\n",
      "part1.encoder.layer.6.attention.attention.query.weight False\n",
      "part1.encoder.layer.6.attention.attention.query.bias False\n",
      "part1.encoder.layer.6.attention.attention.key.weight False\n",
      "part1.encoder.layer.6.attention.attention.key.bias False\n",
      "part1.encoder.layer.6.attention.attention.value.weight False\n",
      "part1.encoder.layer.6.attention.attention.value.bias False\n",
      "part1.encoder.layer.6.attention.output.dense.weight False\n",
      "part1.encoder.layer.6.attention.output.dense.bias False\n",
      "part1.encoder.layer.6.intermediate.dense.weight False\n",
      "part1.encoder.layer.6.intermediate.dense.bias False\n",
      "part1.encoder.layer.6.output.dense.weight False\n",
      "part1.encoder.layer.6.output.dense.bias False\n",
      "part1.encoder.layer.6.layernorm_before.weight False\n",
      "part1.encoder.layer.6.layernorm_before.bias False\n",
      "part1.encoder.layer.6.layernorm_after.weight False\n",
      "part1.encoder.layer.6.layernorm_after.bias False\n",
      "part1.encoder.layer.7.attention.attention.query.weight False\n",
      "part1.encoder.layer.7.attention.attention.query.bias False\n",
      "part1.encoder.layer.7.attention.attention.key.weight False\n",
      "part1.encoder.layer.7.attention.attention.key.bias False\n",
      "part1.encoder.layer.7.attention.attention.value.weight False\n",
      "part1.encoder.layer.7.attention.attention.value.bias False\n",
      "part1.encoder.layer.7.attention.output.dense.weight False\n",
      "part1.encoder.layer.7.attention.output.dense.bias False\n",
      "part1.encoder.layer.7.intermediate.dense.weight False\n",
      "part1.encoder.layer.7.intermediate.dense.bias False\n",
      "part1.encoder.layer.7.output.dense.weight False\n",
      "part1.encoder.layer.7.output.dense.bias False\n",
      "part1.encoder.layer.7.layernorm_before.weight False\n",
      "part1.encoder.layer.7.layernorm_before.bias False\n",
      "part1.encoder.layer.7.layernorm_after.weight False\n",
      "part1.encoder.layer.7.layernorm_after.bias False\n",
      "part1.encoder.layer.8.attention.attention.query.weight False\n",
      "part1.encoder.layer.8.attention.attention.query.bias False\n",
      "part1.encoder.layer.8.attention.attention.key.weight False\n",
      "part1.encoder.layer.8.attention.attention.key.bias False\n",
      "part1.encoder.layer.8.attention.attention.value.weight False\n",
      "part1.encoder.layer.8.attention.attention.value.bias False\n",
      "part1.encoder.layer.8.attention.output.dense.weight False\n",
      "part1.encoder.layer.8.attention.output.dense.bias False\n",
      "part1.encoder.layer.8.intermediate.dense.weight False\n",
      "part1.encoder.layer.8.intermediate.dense.bias False\n",
      "part1.encoder.layer.8.output.dense.weight False\n",
      "part1.encoder.layer.8.output.dense.bias False\n",
      "part1.encoder.layer.8.layernorm_before.weight False\n",
      "part1.encoder.layer.8.layernorm_before.bias False\n",
      "part1.encoder.layer.8.layernorm_after.weight False\n",
      "part1.encoder.layer.8.layernorm_after.bias False\n",
      "part1.encoder.layer.9.attention.attention.query.weight False\n",
      "part1.encoder.layer.9.attention.attention.query.bias False\n",
      "part1.encoder.layer.9.attention.attention.key.weight False\n",
      "part1.encoder.layer.9.attention.attention.key.bias False\n",
      "part1.encoder.layer.9.attention.attention.value.weight False\n",
      "part1.encoder.layer.9.attention.attention.value.bias False\n",
      "part1.encoder.layer.9.attention.output.dense.weight False\n",
      "part1.encoder.layer.9.attention.output.dense.bias False\n",
      "part1.encoder.layer.9.intermediate.dense.weight False\n",
      "part1.encoder.layer.9.intermediate.dense.bias False\n",
      "part1.encoder.layer.9.output.dense.weight False\n",
      "part1.encoder.layer.9.output.dense.bias False\n",
      "part1.encoder.layer.9.layernorm_before.weight False\n",
      "part1.encoder.layer.9.layernorm_before.bias False\n",
      "part1.encoder.layer.9.layernorm_after.weight False\n",
      "part1.encoder.layer.9.layernorm_after.bias False\n",
      "part1.encoder.layer.10.attention.attention.query.weight False\n",
      "part1.encoder.layer.10.attention.attention.query.bias False\n",
      "part1.encoder.layer.10.attention.attention.key.weight False\n",
      "part1.encoder.layer.10.attention.attention.key.bias False\n",
      "part1.encoder.layer.10.attention.attention.value.weight False\n",
      "part1.encoder.layer.10.attention.attention.value.bias False\n",
      "part1.encoder.layer.10.attention.output.dense.weight False\n",
      "part1.encoder.layer.10.attention.output.dense.bias False\n",
      "part1.encoder.layer.10.intermediate.dense.weight False\n",
      "part1.encoder.layer.10.intermediate.dense.bias False\n",
      "part1.encoder.layer.10.output.dense.weight False\n",
      "part1.encoder.layer.10.output.dense.bias False\n",
      "part1.encoder.layer.10.layernorm_before.weight False\n",
      "part1.encoder.layer.10.layernorm_before.bias False\n",
      "part1.encoder.layer.10.layernorm_after.weight False\n",
      "part1.encoder.layer.10.layernorm_after.bias False\n",
      "part1.encoder.layer.11.attention.attention.query.weight False\n",
      "part1.encoder.layer.11.attention.attention.query.bias False\n",
      "part1.encoder.layer.11.attention.attention.key.weight False\n",
      "part1.encoder.layer.11.attention.attention.key.bias False\n",
      "part1.encoder.layer.11.attention.attention.value.weight False\n",
      "part1.encoder.layer.11.attention.attention.value.bias False\n",
      "part1.encoder.layer.11.attention.output.dense.weight False\n",
      "part1.encoder.layer.11.attention.output.dense.bias False\n",
      "part1.encoder.layer.11.intermediate.dense.weight False\n",
      "part1.encoder.layer.11.intermediate.dense.bias False\n",
      "part1.encoder.layer.11.output.dense.weight False\n",
      "part1.encoder.layer.11.output.dense.bias False\n",
      "part1.encoder.layer.11.layernorm_before.weight False\n",
      "part1.encoder.layer.11.layernorm_before.bias False\n",
      "part1.encoder.layer.11.layernorm_after.weight False\n",
      "part1.encoder.layer.11.layernorm_after.bias False\n",
      "part1.layernorm.weight False\n",
      "part1.layernorm.bias False\n",
      "part2.weight True\n",
      "part2.bias True\n",
      "part3.weight True\n",
      "part3.bias True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "my_model = CustomAST(model=ast_model_pure).to(device) #loading the model on the GPU\n",
    "\n",
    "for name, param in my_model.named_parameters():\n",
    "  if 'part1' in name :\n",
    "    param.requires_grad = False # make the original AST part non trainable, so that only the classifier head gets trained\n",
    "  print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZXCXSRfAu3k"
   },
   "source": [
    "I decide to train this model for 5 epochs based on the research done in [THE BIRDS NEED ATTENTION TOO](#https://arxiv.org/pdf/2211.07722.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491436,
     "status": "ok",
     "timestamp": 1705934573960,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "4DlpOoS4gkHQ",
    "outputId": "2b49bd77-085f-4a19-97a8-39ebf034a75c"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:16<00:00,  4.22s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy = 0.830833375453949\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:15<00:00,  4.21s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Accuracy = 0.8462499976158142\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:15<00:00,  4.20s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Accuracy = 0.8611111044883728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:14<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Accuracy = 0.8656250834465027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:14<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Accuracy = 0.8673334121704102\n"
     ]
    }
   ],
   "source": [
    "train_model(my_model, train_loader = train_loader, val_loader = val_loader, n_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74462,
     "status": "ok",
     "timestamp": 1705934668145,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "-0tKLFI0R5lk",
    "outputId": "8246d341-d506-48ab-ed90-6ddacf6ade6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.887619137763977\n"
     ]
    }
   ],
   "source": [
    "predict_model(my_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJE0RkBOCwO6"
   },
   "outputs": [],
   "source": [
    "torch.save(my_model, 'ast_with_my_head.pth')\n",
    "# Remember that you must call model.eval() to set dropout and batch normalization\n",
    "# layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV6iEH5X0HkR"
   },
   "source": [
    "My model is using transfer learning by only adding a trainable head and shows acceptable results just after 5 epochs. Bellow I show some metrixs from MLflow (databricks community cloud is set and used for teh Mlflow):<br>\n",
    "<figure>\n",
    "<img src=\"Accuracy_my_model.png\" style=\"max-height: 200px\" alt=\"accuracy_per_epoch\" />\n",
    "<figcaption align = \"center\"> We can see how the accuracy increases on the validation set on the \"y\" axes (slowly but steady). The time on the \"x\" is relative and represents the time of execution. This graphs are not upto the standards, but further understanding of how to use MLflow is required to make it better.  </figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "<figure>\n",
    "<img src=\"Loss_my_model.png\" style=\"max-height: 200px\" alt=\"Loss_epoch_1\" />\n",
    "<figcaption align = \"center\"> We can see how the Loss from the first epoch is decreasing (train_loss_ep0).While teh loss from the last epoch is relatively stable (train_loss_ep4)  </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anSeTJpGWeFo"
   },
   "source": [
    "<a id='lora'></a>\n",
    "[TOP](#tops)\n",
    "## Adaptation using LoRA ( Low-Rank Adaptation) on my model\n",
    "\n",
    "LoRA freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6321,
     "status": "ok",
     "timestamp": 1706186560879,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "kuKJ4nqvq6N4",
    "outputId": "3aa26d99-c3a0-4792-bfb7-54a0475f00b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 599819 || all params: 86797078 || trainable%: 0.69\n"
     ]
    }
   ],
   "source": [
    "config2 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"part2\",\"part3\"],\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(torch.load('ast_with_my_head.pth'), config2).to(device)\n",
    "print_trainable_parameters(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sq2nie4soKU"
   },
   "source": [
    "As we will train more layers, we shold adjust the size of the batches as shown bellow, so that we could process the larger number of parameters (599816) with the available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdqFRSFiWfBd"
   },
   "outputs": [],
   "source": [
    "testset, valset = random_split(BirdDataset(x_val, y_val), [0.7, 0.3])\n",
    "val_loader_lora = DataLoader(valset, shuffle=True, batch_size=5)\n",
    "test_loader_lora = DataLoader(testset, shuffle=True, batch_size=5)\n",
    "train_loader_lora = DataLoader(BirdDataset(x_tr, y_tr), shuffle=True, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z86Ohj0Qb_os"
   },
   "source": [
    "we will train this for 3 epochs with a smaller Learning rate to imporove the model a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2510324,
     "status": "ok",
     "timestamp": 1706172430735,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "Oub2aQQLS5e5",
    "outputId": "42e6eed0-f444-4c33-8d5f-a83421535156"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 593/593 [13:07<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy = 0.8899999260902405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 593/593 [13:28<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Accuracy = 0.8950003385543823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 593/593 [13:28<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Accuracy = 0.8977782726287842\n"
     ]
    }
   ],
   "source": [
    "train_model(lora_model, train_loader = train_loader_lora, val_loader = val_loader_lora, run_name = 'my_adapter_model2',  n_epochs = 3, lr = 0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79466,
     "status": "ok",
     "timestamp": 1706172510419,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "IyyvLLyXfks5",
    "outputId": "caa51b00-e1f3-4846-eff8-aaa2e212f073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139/139 [01:19<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9093528985977173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_model(lora_model, test_loader = test_loader_lora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYfSHodEeevt"
   },
   "source": [
    "After Lora we can see that the test set accuracy increased by around 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgZ4fmusvJ4X"
   },
   "outputs": [],
   "source": [
    "torch.save(lora_model, 'my_ast_with_lora.pth') # save this version of teh model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q_ZzvZPNnkt"
   },
   "source": [
    "<a id='heads'></a>\n",
    "[TOP](#tops)\n",
    "## Bigger head does not produce better results\n",
    "\n",
    "the model we used above is very simple we just added a layer normalization and then a Dense layer from 768 to 11. As this is big differens in one step it is worth asking: would we get better results if we gradually reach the 11 classes.\n",
    "<br>Bellow i will train 2 models with different heads:<br>\n",
    "option 1:<br>\n",
    "```python\n",
    "        self.part1 = model\n",
    "        self.part2 = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part3 = nn.Linear(in_features=768, out_features=384, bias=True)\n",
    "        self.part4 = nn.LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part5 = nn.Linear(in_features=384, out_features=120, bias=True)\n",
    "        self.part6 = nn.LayerNorm((120,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part7 = nn.Linear(in_features=120, out_features=40, bias=True)\n",
    "        self.part8 = nn.LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part9 = nn.Linear(in_features=40, out_features=11, bias=True)\n",
    "```\n",
    "<br>option 2:<br>\n",
    "```python\n",
    "        self.part1 = model\n",
    "        self.part2 = nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part3 = nn.Linear(in_features=768, out_features=160, bias=True)\n",
    "        self.part4 = nn.LayerNorm((160,), eps=1e-12, elementwise_affine=True)\n",
    "        self.part5 = nn.Linear(in_features=160, out_features=11, bias=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3Wzoei_OqPD"
   },
   "outputs": [],
   "source": [
    "testset, valset = random_split(BirdDataset(x_val, y_val), [0.7, 0.3])\n",
    "val_loader = DataLoader(valset, shuffle=True, batch_size=20)\n",
    "test_loader = DataLoader(testset, shuffle=True, batch_size=20)\n",
    "train_loader = DataLoader(BirdDataset(x_tr, y_tr), shuffle=True, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1My4ZmONogZ"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "tomas_model_1 = TomasAST_1(model=ast_model_pure).to(device)\n",
    "\n",
    "for name, param in tomas_model.named_parameters():\n",
    "  if 'part1' in name :\n",
    "    param.requires_grad = False # make the original AST part non trainable, so that only the classifier head gets trained\n",
    "  # print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1752782,
     "status": "ok",
     "timestamp": 1706433061884,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "vgaGhjysNo-U",
    "outputId": "1ab82b5f-2f47-4787-a7ab-23444140d1ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:16<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy = 0.6983333826065063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:18<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Accuracy = 0.7195833921432495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:17<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Accuracy = 0.7658333778381348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:19<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Accuracy = 0.7860416173934937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:19<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Accuracy = 0.7986665368080139\n"
     ]
    }
   ],
   "source": [
    "train_model(tomas_model_1, train_loader = train_loader, val_loader = val_loader, n_epochs = 5, run_name = 'tomas_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74814,
     "status": "ok",
     "timestamp": 1706434289695,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "C27YDpdzO2KA",
    "outputId": "a31e02f9-d1f4-4d4f-9b54-0c1c930c8a9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [01:14<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.8661904335021973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_model(tomas_model_1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lit9RADaD4i"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "tomas_model_2 = TomasAST_2(model=ast_model_pure).to(device)\n",
    "\n",
    "for name, param in tomas_model_2.named_parameters():\n",
    "  if 'part1' in name :\n",
    "    param.requires_grad = False\n",
    "  print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1753279,
     "status": "ok",
     "timestamp": 1706436167479,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "1oyCYtQsae5O",
    "outputId": "5bb80ae3-6a76-4ede-a148-8c87973fb2d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:18<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy = 0.8250001072883606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:17<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Accuracy = 0.8308334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:17<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Accuracy = 0.8461112380027771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:18<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Accuracy = 0.8518751859664917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [05:18<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Accuracy = 0.8653334975242615\n"
     ]
    }
   ],
   "source": [
    "train_model(tomas_model_2, train_loader = train_loader, val_loader = val_loader, n_epochs = 5, run_name = 'tomas_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74510,
     "status": "ok",
     "timestamp": 1706436242923,
     "user": {
      "displayName": "Tomislav Vasilev",
      "userId": "01320317235636870252"
     },
     "user_tz": -120
    },
    "id": "3HNsApQrbnVB",
    "outputId": "433422e2-d9ba-45ba-87f8-1aaf7b570898"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [01:14<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9047619104385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_model(tomas_model_2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce0ZZFdMf4C7"
   },
   "source": [
    "We can notice that adding layers in the head does not improve the results significantly and we should not be concerned dercreasing the nodes from 768 to 11 in just one Dense layer.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNuwEIk1QLrvKSqjoZbCnu8",
   "collapsed_sections": [
    "YK_DP9ZEfpi4"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "116f2f3931df47f9a26ae9393636419b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_754266195a2b4593b3c6aa5ff6033c92",
       "IPY_MODEL_b8025815f0ab4c01b5e1b4f517078640",
       "IPY_MODEL_9715ac438e284272b5f960bcf0074d91"
      ],
      "layout": "IPY_MODEL_190f08c51419465fabe83119cefdc4a8"
     }
    },
    "144f2baa82254a2b98755b646a0b84bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "190f08c51419465fabe83119cefdc4a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1afe9ff6829a41c292444f1256a46190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d224f159ccb4c7b8a09d4be369ba11c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "393127ec643e4012a13772138b718692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44dc9d65a17a4cb8aa356b4633906f89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ae316d8c2b644ac904cfa322cfd33e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51d5fb7fac2144059662e8f953af306e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44dc9d65a17a4cb8aa356b4633906f89",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4ae316d8c2b644ac904cfa322cfd33e0",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "524a9a68c8bd4343926e88debdd06b0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "566bc31567a84713885a6521ffa956b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb3546d5be8441fa7809622fd3afbb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bbd0d71ae644bab90ab82d9347b9001": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "754266195a2b4593b3c6aa5ff6033c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8473cba201984b64b6b1566f9424ace0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f24baf67c4e64e13ae2ccb31a4476146",
      "value": "config.json: 100%"
     }
    },
    "76a8266814464115b36c107002763421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_524a9a68c8bd4343926e88debdd06b0d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b7a572065cf84f5fa16ea97e35600e9f",
      "value": "model.safetensors: 100%"
     }
    },
    "772d0bc227af43528b256b31c19f6e3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "797d4f9f4e8d4754913c52695f3d3943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1afe9ff6829a41c292444f1256a46190",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_393127ec643e4012a13772138b718692",
      "value": " 297/297 [00:00&lt;00:00, 4.89kB/s]"
     }
    },
    "79946a9fb1da4321858b0b386df0647b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b7beeae8b004c76803dc9e355cc1c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bbd0d71ae644bab90ab82d9347b9001",
      "max": 297,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79946a9fb1da4321858b0b386df0647b",
      "value": 297
     }
    },
    "810fe31d22c740a5a604588ca17e67a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8473cba201984b64b6b1566f9424ace0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8945c5cc80ca4b8cb0927f1a3f41a254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8478567ff384b3aa4b25ee5494aaae2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_810fe31d22c740a5a604588ca17e67a0",
      "value": " 346M/346M [00:06&lt;00:00, 40.0MB/s]"
     }
    },
    "9715ac438e284272b5f960bcf0074d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_566bc31567a84713885a6521ffa956b2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e199485560884c7b8051c5f0170e1ac7",
      "value": " 26.8k/26.8k [00:00&lt;00:00, 1.37MB/s]"
     }
    },
    "9de97399f81c4aa7b667ea3b12e7f666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76a8266814464115b36c107002763421",
       "IPY_MODEL_ee9f499d668e4ad2b272c93087802aa9",
       "IPY_MODEL_8945c5cc80ca4b8cb0927f1a3f41a254"
      ],
      "layout": "IPY_MODEL_d2df2603ba174484a462c631629d0f0c"
     }
    },
    "b7a572065cf84f5fa16ea97e35600e9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8025815f0ab4c01b5e1b4f517078640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d224f159ccb4c7b8a09d4be369ba11c",
      "max": 26763,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_144f2baa82254a2b98755b646a0b84bd",
      "value": 26763
     }
    },
    "c8478567ff384b3aa4b25ee5494aaae2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce75bc4d57a04bbaa27e1679c1d83fb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51d5fb7fac2144059662e8f953af306e",
       "IPY_MODEL_7b7beeae8b004c76803dc9e355cc1c24",
       "IPY_MODEL_797d4f9f4e8d4754913c52695f3d3943"
      ],
      "layout": "IPY_MODEL_772d0bc227af43528b256b31c19f6e3c"
     }
    },
    "d2df2603ba174484a462c631629d0f0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e199485560884c7b8051c5f0170e1ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee9f499d668e4ad2b272c93087802aa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb3546d5be8441fa7809622fd3afbb4",
      "max": 346404948,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f946159f57e7446eb971dc6d1783047e",
      "value": 346404948
     }
    },
    "f24baf67c4e64e13ae2ccb31a4476146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f946159f57e7446eb971dc6d1783047e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
